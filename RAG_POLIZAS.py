# App RAG para pÃ³lizas 
# ---------------------------------------------------------------
# Cambios mÃ­nimos:
# - Acepta .txt
# - Usa CharacterTextSplitter + SentenceTransformerEmbeddings + FAISS
# - Usa RetrievalQA (patrÃ³n clÃ¡sico) con ChatOpenAI si hay API key

import os
import streamlit as st
from dotenv import load_dotenv
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI  # âœ… IMPORT CORRECTO PARA CHAT
from langchain.chains import RetrievalQA

# ---------------------------------------------------------------------
# ğŸ”¹ Cargar la API key
# ---------------------------------------------------------------------
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    st.error("âš ï¸ No se encontrÃ³ la variable OPENAI_API_KEY. Usa 'echo \"OPENAI_API_KEY=tu_api_key\" >> .env'")
else:
    os.environ["OPENAI_API_KEY"] = api_key

# ---------------------------------------------------------------------
# ğŸ”¹ ConfiguraciÃ³n de Streamlit
# ---------------------------------------------------------------------
st.set_page_config(page_title="RAG de PÃ³lizas", layout="centered")
st.title("Asistente para consultar pÃ³lizas de seguro en texto plano")

st.sidebar.header("ğŸ’¡ Sugerencias de preguntas")
st.sidebar.markdown("""
- Â¿QuÃ© cubre la pÃ³liza?
- Â¿CuÃ¡l es el deducible aplicable?
- Â¿QuÃ© hacer en caso de siniestro?
""")

# ---------------------------------------------------------------------
# ğŸ”¹ Subida de archivo y pregunta
# ---------------------------------------------------------------------
uploaded_file = st.file_uploader("Sube el archivo de pÃ³liza (.txt)", type=["txt"])
user_query = st.text_input("Escribe tu pregunta:")
search_button = st.button("Buscar")

# ---------------------------------------------------------------------
# ğŸ”¹ Procesamiento del documento
# ---------------------------------------------------------------------
if uploaded_file:
    text = uploaded_file.read().decode("utf-8")

    with st.spinner("Construyendo el Ã­ndice vectorial..."):
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=150,
            separators=["\n\n", "\n", ".", " ", ""]
        )
        chunks = splitter.split_text(text)

        embeddings = OpenAIEmbeddings(openai_api_key=api_key)
        vectorstore = FAISS.from_texts(chunks, embeddings)

        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

        # âœ… Usamos modelo de chat moderno
        llm = ChatOpenAI(
            temperature=0,
            openai_api_key=api_key,
            model_name="gpt-3.5-turbo"
        )

        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever
        )

    st.success("âœ… Ãndice vectorial construido correctamente.")

    # -----------------------------------------------------------------
    # ğŸ”¹ Responder preguntas
    # -----------------------------------------------------------------
    if search_button and user_query:
        with st.spinner("Buscando respuesta..."):
            result = qa_chain.run(user_query)
        st.markdown(f"**Respuesta:** {result}")

else:
    st.info("ğŸ“„ Por favor, sube un archivo de texto (.txt) para comenzar.")